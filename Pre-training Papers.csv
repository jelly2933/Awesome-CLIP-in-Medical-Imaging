Name,Publications,Year,pdf,Data,taxonomy,comment,Area
Joint Modeling of Chest Radiographs and Radiology Reports for Pulmonary Edema Assessment,MICCAI,2021 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Chauhan_et_al._-_2020_-_Joint_Modeling_of_Chest_Radiographs_and_Radiology_.pdf,CXR,base,"contrastive loss, together with classification loss of edema level",
GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-efficient Medical Image Recognition,ICCV,2021 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Huang_et_al._-_2021_-_GLoRIA_A_Multimodal_Global-Local_Representation_L.pdf,CXR,fine-grained contrast,adopte weighted average image representation for each word representation,
Multimodal Representation Learning via Maximization of Local Mutual Information,MICCAI,2021 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Liao_%25E7%25AD%2589_-_2021_-_Multimodal_Representation_Learning_via_Maximizatio.pdf,CXR,global-local,very similar. It choose argmax image representation instead of the weighted average version,
Contrastive Learning of Medical Visual Representations from Paired Images and Text,MLHC,2022 (arXiv 2020),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Zhang_et_al._-_2022_-_Contrastive_Learning_of_Medical_Visual_Representat.pdf,CXR,base,earlier than clip,
Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning,NIPS,2022 (December),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Wang_et_al._-_2022_-_Multi-Granularity_Cross-modal_Alignment_for_Genera.pdf,CXR,data-efficient,"perform hierarchical alignment at disease-level, instance-level, and pathological region-level",
MedCLIP: Contrastive Learning from Unpaired Medical Images and Text,EMNLP,2022 (December),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Wang_%25E7%25AD%2589_-_2022_-_MedCLIP_Contrastive_Learning_from_Unpaired_Medica.pdf,CXR,data-efficient,"idea from DeCLIP ",
The Role of Local Alignment and Uniformity in Image-Text Contrastive Learning on Medical Images,NIPS,2022 (December),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Mller_%25E7%25AD%2589_-_2023_-_The_Role_of_Local_Alignment_and_Uniformity_in_Imag.pdf,CXR,global-local related,It aruges that local contrast can be replaced by distribution prior,
Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports,Nature Machine Intelligence,2022 (January),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Zhou_et_al._-_2022_-_Generalized_radiograph_representation_learning_via.pdf,CXR,base (multi-task)," add a report generation decoder.
report generation loss + clip loss",
Making the Most of Text Semantics to Improve Biomedical Vision–Language Processing,ECCV,2022 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Boecking_et_al._-_2022_-_Making_the_Most_of_Text_Semantics_to_Improve_Biome.pdf,CXR,data-efficient,"BioVIL
data augmentation such as finding/impression shuffle",
Breaking with Fixed Set Pathology Recognition through Report-Guided Contrastive Training,MICCAI,2022 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Seibold_%25E7%25AD%2589_-_2022_-_Breaking_with_Fixed_Set_Pathology_Recognition_thro.pdf,CXR,global-local,"global: image-report contrastive
local: image-sentence contrastive",
Joint Learning of Localized Representations from Medical Images and Reports,ECCV,2022 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Mller_et_al._-_2021_-_Joint_Learning_of_Localized_Representations_from_M.pdf,CXR,global-local,"similar with GLoRIA. Instead fo weighted average representation, it adopts transformers QKV to compute cross-model local representation",
"Vision-Language Contrastive Learning
Approach to Robust Automatic Placenta
Analysis Using Photographic Images",MICCAI,2022 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Vision_Language_Contrastive_Learning.pdf,placeta,fine-grained,,
"Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge",ACM MM,2022 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Chen_%25E7%25AD%2589_-_2022_-_Align_Reason_and_Learn_Enhancing_Medical_Vision-.pdf,CXR,knowledge-enhanced,guide the model to put emphasis on the most critical information in images and texts by designing knowledge-induced pretext tasks,
Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining,,2023 (April),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Lin_%25E7%25AD%2589_-_2023_-_Towards_Medical_Artificial_General_Intelligence_vi.pdf,CXR,knowledge-enhanced,,
A Foundation LAnguage-Image model of the Retina (FLAIR): Encoding expert knowledge in text supervision,arXiv,2023 (August),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Silva-Rodriguez_%25E7%25AD%2589_-_2023_-_A_Foundation_LAnguage-Image_model_of_the_Retina_(F.pdf,Retina,knowledge,,
Advancing Radiograph Representation Learning with Masked Record Modeling,ICLR,2023 (February),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Zhou_%25E7%25AD%2589_-_2023_-_ADVANCING_RADIOGRAPH_REPRESENTATION_LEARN-_ING_WIT.pdf,CXR,fine-grained,,
"Improving Medical Vision-Language Contrastive
Pretraining with Semantics-aware Triage",IEEE TMI,2023 (July),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Improving_Medical_Vision-Language_Contrastive_Pretraining_with_Semantics-aware_Triage.pdf,CXR,data-efficient,construct addtional positive pair given report semantics,
Unified Medical Image-Text-Label Contrastive Learning With Continuous Prompt,BIBM,2023 (July),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Wang_-_2023_-_Unified_Medical_Image-Text-Label_Contrastive_Learn.pdf,CXR,data-efficient,,
"Towards a Visual-Language Foundation Model for
Computational Pathology",Nature Medicine,2023 (July),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Towards_a_Visual.pdf,WSI,others,,
Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images,ICCV,2023 (June),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Lu_et_al._-_2023_-_Visual_Language_Pretrained_Multiple_Instance_Zero-.pdf,WSI,,,
PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents,MICCAI,2023 (March),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/978-3-031-43993-3_51.pdf,general,data,,
"Significantly Improving Zero-Shot X-ray Pathology Classification
via Fine-tuning Pre-trained Image-Text Encoders",,2023 (March),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Jang_%25E7%25AD%2589_-_2023_-_Significantly_Improving_Zero-Shot_X-ray_Pathology_.pdf,CXR,data-efficient,,
Local Contrastive Learning for Medical Image Recognition,arXiv,2023 (March),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Rizvi_%25E7%25AD%2589_-_2023_-_Local_Contrastive_Learning_for_Medical_Image_Recog.pdf,CXR,global-local,add region-selection,
Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing,,2023 (March),,general,,,
Learning to Exploit Temporal Structure for Biomedical Vision–Language Processing,CVPR,2023 (May),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Bannur_et_al._-_2023_-_Learning_to_Exploit_Temporal_Structure_for_Biomedi.pdf,CXR,data-efficient,temporal version of BioVIL,
Self-supervised multi-modal training from uncurated images and reports enables monitoring AI in radiology,MedIA,2023 (Novmber),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Park_%25E7%25AD%2589_-_2024_-_Self-supervised_multi-modal_training_from_uncurate.pdf,,,,
TCSA: A Text-Guided Cross-View Medical Semantic Alignment Framework for Adaptive Multi-view Visual Representation Learning,,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Lei_%25E7%25AD%2589_-_2023_-_TCSA_A_Text-Guided_Cross-View_Medical_Semantic_Al.pdf,CXR,"data efficient
global-local",,
CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training,MICCAI,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/You_et_al._-_2023_-_CXR-CLIP_Toward_Large_Scale_Chest_X-ray_Language-.pdf,CXR,data-efficient,utilize prompting for training in CXR domain. the prompt is features by the description of uncertainty,
SDA-CLIP: surgical visual domain adaptation using video and text labels,,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Li_%25E7%25AD%2589_-_2023_-_SDA-CLIP_surgical_visual_domain_adaptation_using_.pdf,Surgical,data-efficient,,
IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training,arXiv,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Liu_%25E7%25AD%2589_-_2023_-_IMITATE_Clinical_Prior_Guided_Hierarchical_Vision.pdf,CXR,data-efficient (mine the hierarchical structure of medical report),The framework derives multi-level visual features from the chest X-ray (CXR) images and separately aligns these features with the descriptive and the conclusive text encoded in the hierarchical medical report,
Enhancing Automatic Placenta Analysis through Distributional Feature Recomposition in Vision-Language Contrastive Learning,MICCAI,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/978-3-031-43987-2_12.pdf,placeta,fine-grained,,
Multi-task Paired Masking with Alignment Modeling for Medical Vision-Language Pre-training,IEEE TMM,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Zhang_%25E7%25AD%2589_-_2023_-_Multi-task_Paired_Masking_with_Alignment_Modeling_.pdf,CXR,fine-grained,,
PRIOR: Prototype Representation Joint Learning from Medical Images and Reports,ICCV,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Cheng_%25E7%25AD%2589_-_2023_-_PRIOR_Prototype_Representation_Joint_Learning_fro.pdf,CXR,global-local,a cross-modality conditional reconstruction module is designed to interchange information across modalities in the training phase by reconstructing masked images and reports.,
LIMITR: Leveraging Local Information for Medical Image-Text Representation,ICCV,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation.pdf,CXR,global-local&knowledge,trash paper,
MITER: Medical Image-TExt joint adaptive pretRaining with multi-level contrastive learning,,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Shu_%25E7%25AD%2589_-_2023_-_MITER_Medical_Image-TExt_joint_adaptive_pretRaini.pdf,CXR,it’s just ALBEF,,
MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis,ICCV,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Wu_et_al._-_MedKLIP_Medical_Knowledge_Enhanced_Language-Image.pdf,CXR,knowledge enhanced,,
Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-Training,MICCAI,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Chen_%25E7%25AD%2589_-_2023_-_Knowledge_Boosting_Rethinking_Medical_Contrastive.pdf,CXR,knowledge enhanced,trash paper,
M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization,MICCAI,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/978-3-031-43907-0_61.pdf,CXR,others,"frozen text encoder, train image encoder only ",
Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts,ICCV,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf,CXR,others,pseudo prompt pool,
Pathology-and-genomics Multimodal Transformer for Survival Outcome Prediction,MICCAI,2023 (October),,WSI,others,,
"Quilt-1M: One Million Image-Text Pairs for
Histopathology",NIPS,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Quilt_1M.pdf,WSI,,,
"Surgical Video Captioning
with Mutual-Modal Concept Alignment",MICCAI,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Chen_%25E7%25AD%2589_-_2023_-_Surgical_Video_Captioning_with_Mutual-Modal_Concep.pdf,Surgical,,"it adopts  surgical concept(prototype) representations for image and text modality, respectively",
Cross-Modal Translation and Alignment for Survival Analysis,ICCV,2023 (October),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Zhou_%25E5%2592%258C_Chen_-_Cross-Modal_Translation_and_Alignment_for_Survival.pdf,WSI,,,
UniBrain: Universal Brain MRI Diagnosis with Hierarchical Knowledge-enhanced Pre-training,arXiv,2023 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Lei_%25E7%25AD%2589_-_2023_-_UniBrain_Universal_Brain_MRI_Diagnosis_with_Hiera.pdf,Brain MRI,data efficient,"multi-report contrast
hierarchical",
Cascaded Contrastive Medical Language-Image Pretraining on Radiology Images,arXiv,2023 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/4168_cascaded_contrastive_medical_l.pdf,CXR,"data-efficient ","太捞了
hierarchical",
TIER: Text-Image Entropy Regularization for Medical CLIP-style models,MLHC,2023 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Palepu_-_TIER_Text-Image_Entropy_Regularization_for_Medica.pdf,CXR,global-local,,
Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias,arXiv,2023 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Wan_et_al._-_2023_-_Med-UniC_Unifying_Cross-Lingual_Medical_Vision-La.pdf,CXR,others,attempt to diminish the language bias between spanish report and english report,
A visual–language foundation model for pathology image analysis using medical Twitter,Nature Medicine,2023 (September),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Huang_et_al._-_2023_-_A_visuallanguage_foundation_model_for_pathology_i.pdf,WSI,,,
Contrastive Masked Image-Text Modeling for Medical Visual Representation Learning,,,,,,,
G2D: From Global to Dense Radiography Representation Learning via Vision-Language Pre-training,,2023 (December),,,,,
Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images,,2023 (December),,,,,
https://aclanthology.org/2023.emnlp-main.989.pdf,EMNLP,2023 (December),,CXR,,,
CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification,CVPR,2024 (March),%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%B7%AF%E5%B7%A5%E4%BD%9C%E5%AE%A4%20(clip%20survey)%204f00cf997b7641aebce31e6e6ce0e0ab/Lai_CARZero_Cross-Attention_Alignment_for_Radiology_Zero-Shot_Classification_CVPR_2024_paper.pdf,,global-local,,
MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning,CVPR,2024 (March),,,knowledge,,
PairAug: What Can Augmented Image-Text Pairs Do for Radiology?,CVPR,2024 (March),,,data-efficient,,
https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Bootstrapping_Chest_CT_Image_Understanding_by_Distilling_Knowledge_from_X-ray_CVPR_2024_paper.html,CVPR,2024 (March),,,data-efficient,,
Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework,CVPR,2024 (March),,,data-efficient,,
Improving Medical Multi-modal Contrastive Learning with Expert Annotations,ECCV,2024 (March),,,,,
"Multi-Grained Radiology Report Generation With
Sentence-Level Image-Language
Contrastive Learning",IEEE TMI,2024 (Feb),,,global-local,,
"UniChest: Conquer-and-Divide Pre-training for
Multi-Source Chest X-Ray Classification",IEEE TMI,2024 (March),,,others,,
"DeViDe: Faceted medical knowledge for improved
medical vision-language pre-training",arXiv,2024 (April),,,knowledge,,
Knowledge-enhanced Visual-Language Pretraining for Computational Pathology,arXiv,2024 (April),,WSI,knowledge,,
"MeDSLIP: Medical Dual-Stream Language-Image
Pre-training for Fine-grained Alignment",arXiv,2024 (March),,,global-local&knowledge,,
Anatomical Structure-Guided Medical Vision-Language Pre-training,arXiv,2024 (March),,,global-local,,
Benchmarking Vision-Language Contrastive Methods for Medical Representation Learning,arXiv,2024 (Jun),,,,,
Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training,ICML,2024 (May),,,global-local,,
"Align as Ideal: Cross-Modal Alignment Binding for
Federated Medical Vision-Language Pre-training",arXiv,2024 (May),,,others(federated learning),,
"SELF-SUPERVISED VISION-LANGAGE ALIGNMENT OF DEEP
LEARNING REPRESENTATIONS FOR BONE X-RAYS ANALYSIS",arXiv,2024 (May),,,,,
MLIP: Medical Language-Image Pre-training with Masked Local Representation Learning,arXiv,2024 (Jan),,,,,
"CT-GLIP: 3D Grounded Language-Image
Pretraining with CT Scans and Radiology
Reports for Full-Body Scenarios",arXiv,2024 (Apr),,,global-local,,
"SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity,
ECG and Respiratory Signals",ICML,2024 (May),,,,,
"Eye-gaze Guided Multi-modal Alignment for
Medical Representation Learning",arXiv,2024 (March),,,data-efficient,,
RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports,MICCAI,2024 (May),,,data-efficient,,
"Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and
Robustness in Mammography",MICCAI,2024 (May),,,data-efficient,,
"Knowledge-grounded Adaptation Strategy for
Vision-language Models: Building Unique
Case-set for Screening Mammograms for
Residents Training",arXiv,2024 (May),,,knowledge,,
Open Challenges and Opportunities in Federated Foundation Models Towards Biomedical Healthcare,arXiv,2024 (May),,,others,,
Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray,arXiv,2024 (April),,,knowledge&global-local,,
https://arxiv.org/abs/2401.10501,arXiv,2024 (Jan),,,global-local,,
Design as Desired: Utilizing VQA for Multimodal Pre-training,arXiv,2024 (April),,,data-efficient,,
Multi-modal vision-language model for generalizable annotation-free pathology localization and clinical diagnosis,arXiv,2024 (Jan),,,global-local,,
Enhancing the vision-language foundation model with key semantic knowledge-emphasized report refinement,arXiv,2024 (Jan),,,knowledge&data-efficient,,
Freeze the Backbones: a Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-Training,ICASSP,2024 (April),,,others,,
MedFLIP: Medical Vision-and-Language Self-supervised Fast Pre-Training with Masked Autoencoder,,2024 (May),,,knowledge,,
"MEDBind: Unifying Language and Multimodal
Medical Data Embeddings",,2024 (March),,,others,,
Enhancing Representation in Medical Vision-Language Foundation Models via Multi-Scale Information Extraction Techniques,arXiv,2024 (Feb),,,global-local,,
Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination,CAI,,,,data-efficient&global-local,,
RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training,arXiv,2024 (March),,,,,
VisionCLIP: An Med-AIGC based Ethical Language-Image Foundation Model for Generalizable Retina Image Analysis,arXiv,2024 (March),,,,,
Medical Vision-Language Pre-Training for Brain Abnormalities,arXiv,2024 (April),,,others,,
HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition,MICCAI,2024 (May),,Surgical,,,
Backdoor Attack on Un-paired Medical Image-Text Pretrained Models: A Pilot Study on MedCLIP,SaTML,2024 (March),,CXR,others,,
CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment,CVPR,2024 (Jun),,WSI,data-efficient,,
MeDSLIP: Medical Dual-Stream Language-Image Pre-training for Fine-grained Alignment,arXiv,2024(March),,,,,
"Merlin: A Vision Language Foundation Model for 3D
Computed Tomography",arXiv,2024 (Jun),,CT,data-efficient,,
Vision–language foundation model for echocardiogram interpretation,Nature Medicine,2024 (April),,echocardiogram,others,,
Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures,arXiv,2023 (Jun),,Surgical,data-efficient,,